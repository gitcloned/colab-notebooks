{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitcloned/colab-notebooks/blob/master/RVL%20CDIP%20Trained%20Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOp-BrK0alc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c5513ccc-314c-478a-8d5e-2f326d62dcf2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_nMoUYzbCSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-Czk7eMbEMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a45d8e2-2e81-4a9b-d50c-6a7a4bc64feb"
      },
      "source": [
        "from keras import backend as K\n",
        "# from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "from keras.applications import VGG16 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsoWB3DubXh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c1abd901-a8ba-4a96-cfe3-fa68cd593c3a"
      },
      "source": [
        "K.set_image_data_format('channels_first')\n",
        "th_dim_model = VGG16(include_top=True, weights=None, input_shape=(3,224,224), pooling=None, classes=16) # Create your theano model here with TH dim ordering\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "tf_dim_model = VGG16(include_top=True, weights=None, input_shape=(224,224,3), pooling=None, classes=16) # Create your tensorflow model with TF dimordering here\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 19:08:55.609333 140159198549888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0827 19:08:55.671626 140159198549888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0827 19:08:55.679924 140159198549888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0827 19:08:55.701600 140159198549888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0827 19:08:55.702610 140159198549888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0827 19:08:56.071717 140159198549888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7lXL2yebbax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_weights = ['vgg16_weights_th_dim_ordering_th_kernels_Holistic_91.11.h5']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXthvUtUbi9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_rows(original_w, nb_last_conv, nb_rows_dense):\n",
        "    ''' Note :\n",
        "    This algorithm to shuffle dense layer rows was provided by Kent Sommers (@kentsommer)\n",
        "    in a gist : https://gist.github.com/kentsommer/e872f65926f1a607b94c2b464a63d0d3\n",
        "    '''\n",
        "    converted_w = np.zeros(original_w.shape)\n",
        "    count = 0\n",
        "    for index in range(original_w.shape[0]):\n",
        "        if (index % nb_last_conv) == 0 and index != 0:\n",
        "            count += 1\n",
        "        new_index = ((index % nb_last_conv) * nb_rows_dense) + count\n",
        "        #print(\"index from \" + str(index) + \" -> \" + str(new_index))\n",
        "        converted_w[index] = original_w[new_index]\n",
        "\n",
        "    return converted_w\n",
        "\n",
        "\n",
        "first_dense = True\n",
        "nb_last_conv = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6GW11Y5bnh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_folder = '/content/gdrive/My Drive/Research/OCR/C0002/'\n",
        "dirpath = root_folder + \"tf-kernels-channels-last-dim-ordering/\"\n",
        "if not os.path.exists(dirpath):\n",
        "    os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4uLP4Cyb25v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "f3b42255-2190-4deb-d3d8-e1efb5b2401d"
      },
      "source": [
        "K.set_image_dim_ordering('th')\n",
        "for weight_fn in model_weights:\n",
        "    th_dim_model.load_weights(root_folder + weight_fn) # th-kernels-th-dim\n",
        "    #convert_all_kernels_in_model(th_dim_model) # tf-kernels-th-dim // ALREADY DONE BY KERAS!\n",
        "\n",
        "    count_dense = 0\n",
        "    for layer in th_dim_model.layers:\n",
        "        if layer.__class__.__name__ == \"Dense\":\n",
        "            count_dense += 1\n",
        "\n",
        "    if count_dense == 1:\n",
        "        first_dense = False # If there is only 1 dense, no need to perform row shuffle in Dense layer\n",
        "\n",
        "    print(\"Nb layers : \", len(th_dim_model.layers))\n",
        "\n",
        "    for index, th_layer in enumerate(th_dim_model.layers):\n",
        "        if th_layer.__class__.__name__ in ['Conv1D',\n",
        "                                           'Conv2D',\n",
        "                                           'Conv3D',\n",
        "                                           'AtrousConvolution1D'\n",
        "                                           'AtrousConvolution2D',\n",
        "                                           'Conv2DTranspose',\n",
        "                                           'SeparableConv2D',\n",
        "                                           'DepthwiseConv2D',\n",
        "                                           ]:\n",
        "            weights = th_layer.get_weights() # tf-kernels-th-dim\n",
        "            #weights[0] = weights[0].transpose((2, 3, 1, 0)) // ALREADY DONE BY KERAS!\n",
        "            tf_dim_model.layers[index].set_weights(weights) # tf-kernels-tf-dim\n",
        "\n",
        "            nb_last_conv = th_layer.filters # preserve last number of convolutions to use with dense layers // UPDATED from nb_filters\n",
        "            print(\"Converted layer %d : %s\" % (index + 1, th_layer.name))\n",
        "        else:\n",
        "            if th_layer.__class__.__name__ == \"Dense\" and first_dense:\n",
        "                weights = th_layer.get_weights()\n",
        "                nb_rows_dense_layer = weights[0].shape[0] // nb_last_conv\n",
        "\n",
        "                print(\"Magic Number 1 : \", nb_last_conv)\n",
        "                print(\"Magic nunber 2 : \", nb_rows_dense_layer)\n",
        "\n",
        "                weights[0] = shuffle_rows(weights[0], nb_last_conv, nb_rows_dense_layer)\n",
        "                tf_dim_model.layers[index].set_weights(weights)\n",
        "\n",
        "                first_dense = False\n",
        "                print(\"Shuffled Dense Weights layer and saved %d : %s\" % (index + 1, th_layer.name))\n",
        "            else:\n",
        "                tf_dim_model.layers[index].set_weights(th_layer.get_weights())\n",
        "                print(\"Saved layer %d : %s\" % (index + 1, th_layer.name))\n",
        "\n",
        "  \n",
        "    tf_dim_model.save_weights(\"/content/gdrive/My Drive/Research/OCR/C0002/tf-kernels-channels-last-dim-ordering/%s\" % weight_fn, overwrite=True)\n",
        "    print(\"Done tf-kernels-channels-last-dim-ordering %s\" % weight_fn)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  return np.copy(kernel[slices])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Nb layers :  23\n",
            "Saved layer 1 : input_1\n",
            "Converted layer 2 : block1_conv1\n",
            "Converted layer 3 : block1_conv2\n",
            "Saved layer 4 : block1_pool\n",
            "Converted layer 5 : block2_conv1\n",
            "Converted layer 6 : block2_conv2\n",
            "Saved layer 7 : block2_pool\n",
            "Converted layer 8 : block3_conv1\n",
            "Converted layer 9 : block3_conv2\n",
            "Converted layer 10 : block3_conv3\n",
            "Saved layer 11 : block3_pool\n",
            "Converted layer 12 : block4_conv1\n",
            "Converted layer 13 : block4_conv2\n",
            "Converted layer 14 : block4_conv3\n",
            "Saved layer 15 : block4_pool\n",
            "Converted layer 16 : block5_conv1\n",
            "Converted layer 17 : block5_conv2\n",
            "Converted layer 18 : block5_conv3\n",
            "Saved layer 19 : block5_pool\n",
            "Saved layer 20 : flatten\n",
            "Saved layer 21 : fc1\n",
            "Saved layer 22 : fc2\n",
            "Saved layer 23 : predictions\n",
            "Done tf-kernels-channels-last-dim-ordering vgg16_weights_th_dim_ordering_th_kernels_Holistic_91.11.h5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}